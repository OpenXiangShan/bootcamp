{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72f6be59",
   "metadata": {},
   "source": [
    "# Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb898208",
   "metadata": {},
   "source": [
    "为了评估性能，我们通常需要通过仿真（例如，使用 verilator 进行纯软件仿真，或使用 FPGA 或模拟器进行硬件加速仿真）来运行基准测试。\n",
    "\n",
    "To evaluate performance, we usually run benchmark suites via simulation (i.e. software simulation using verilator, hardware-accelerated simulation using FPGA/emulator).\n",
    "\n",
    "然而，现有的方针手段各自存在问题：\n",
    "- 纯软件仿真太慢了；\n",
    "- FPGA片上资源受限，难以用在 XiangShan 这样的复杂设计上；\n",
    "- 模拟器太贵了。\n",
    "\n",
    "However, existing approaches each have their own challenges:\n",
    "- Software simulation is too slow;\n",
    "- FPGA has limited on-chip resources, making it difficult to use for complex designs like XiangShan;\n",
    "- Emulators are too expensive.\n",
    "\n",
    "我们了解到有一些工作在尝试加速软件仿真、或改进 FPGA 的可用性。与此同时，我们认为利用 checkpoint 机制来减少需要仿真的指令数、提高仿真并行度也是一个更简单有效的思路。\n",
    "\n",
    "We have seen some works trying to accelerate software simulation or improve FPGA usability. Meanwhile, we think using checkpointing to reduce the number of instructions that need to be simulated and increase simulation parallelism is also a simpler and more effective approach.\n",
    "\n",
    "![intro](../images/03-performance/01-checkpoint/intro-en.png)\n",
    "\n",
    "Checkpoint 机制简单说就是选取程序运行过程的一些片段，保存下这些片段开始时的体系结构状态（即寄存器和内存），以后每次仿真时都从保存的状态开始运行，直到片段结束。\n",
    "\n",
    "Checkpointing simply means selecting some segments of a program's execution, saving the architectural state (i.e. registers and memory) at the beginning of these segments, and later starting simulation from the saved state each time, until the end of the segment.\n",
    "\n",
    "来自同一程序的不同片段可以并行仿真，从而提高仿真并行度。\n",
    "\n",
    "Different segments from the same program can be simulated in parallel, thus increasing simulation parallelism.\n",
    "\n",
    "随后，通过对每个片段采集到的性能数据进行加权平均，可以估算运行整个程序的性能数据。\n",
    "\n",
    "Then, by taking a weighted average of the performance data collected for each segment, we can estimate the performance data for running the entire program.\n",
    "\n",
    "常见的选取片段的方法有两种：\n",
    "1. 均一采样，即每隔固定指令数选取一个片段；\n",
    "2. SimPoint，即通过 profiling 选取能代表程序整体行为的片段。\n",
    "\n",
    "Common methods for selecting segments include:\n",
    "1. Uniform sampling, i.e., selecting a segment every fixed number of instructions;\n",
    "2. SimPoint sampling, i.e., selecting segments that can represent the overall behavior of the program by profiling.\n",
    "\n",
    "![method](../images/03-performance/01-checkpoint/method-en.png)\n",
    "\n",
    "我们将在本节中演示 SimPoint 如何对程序进行 profiling，生成 checkpoint，并使用 checkpoint 进行仿真。\n",
    "\n",
    "In this section, we will demonstrate how SimPoint profiles a program, generates checkpoints, and runs simulations using checkpoints."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec68f27",
   "metadata": {},
   "source": [
    "本节中会用到一些与 `../env.sh` 不同的路径和常量，为了方便使用，我们创建了一个 `01-env.sh`，在本节中我们将使用该脚本设置环境变量，您可以运行下面的单元格查看这些环境变量\n",
    "\n",
    "This section will use some paths and constants different from `../env.sh`. For convenience, we have created a `01-env.sh`. In this section, we will use this script to set environment variables. You can run the following cell to view these environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad19b46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "source 01-env.sh\n",
    "\n",
    "env | grep WORKLOAD= # workload to be simulated / profiled / checkpointed\n",
    "env | grep CHECKPOINT_INTERVAL=\n",
    "env | grep NEMU=\n",
    "env | grep _HOME\n",
    "env | grep _PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedae1d2",
   "metadata": {},
   "source": [
    "要进行切片，我们首先需要编译 SimPoint 和 NEMU（切片模式），并生成切片恢复器。\n",
    "\n",
    "To perform checkpointing, we need to compile SimPoint and NEMU (in checkpoint mode), and generate a checkpoint restorer first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3c7693",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "source 01-env.sh\n",
    "\n",
    "cd ${NEMU_HOME}\n",
    "git submodule update --init\n",
    "\n",
    "# Compile simpoint generator\n",
    "cd ${NEMU_HOME}/resource/simpoint/simpoint_repo\n",
    "make clean\n",
    "make\n",
    "\n",
    "# Compile NEMU in checkpoint mode\n",
    "cd ${NEMU_HOME}\n",
    "make clean\n",
    "make riscv64-xs-cpt_defconfig\n",
    "make -j8\n",
    "\n",
    "# Generate checkpoint restorer for ${WORKLOAD}\n",
    "cd ${NEMU_HOME}/resource/gcpt_restore\n",
    "rm -rf ${GCPT_PATH}\n",
    "make -C ${NEMU_HOME}/resource/gcpt_restore/ \\\n",
    "    O=${GCPT_PATH} \\\n",
    "    GCPT_PAYLOAD_PATH=$(get_asset workload/${WORKLOAD}.bin) \\\n",
    "    CROSS_COMPILE=riscv64-linux-gnu-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b078a55",
   "metadata": {},
   "source": [
    "接下来，我们需要使用 NEMU 运行要进行切片的程序，来收集程序行为用于 profiling。\n",
    "\n",
    "Next, we need to run the program to be checkpointed using NEMU to collect program behavior for profiling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6105c94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "source 01-env.sh\n",
    "\n",
    "rm -rf ${RESULT_PATH}\n",
    "\n",
    "_LOG_PATH=${LOG_PATH}/profiling\n",
    "mkdir -p ${_LOG_PATH}\n",
    "\n",
    "# ${GCPT}:            workload is checkpoint restorer\n",
    "# -w:                 the actual workload is ${WORKLOAD}\n",
    "# -D:                 the result will be saved to ${RESULT_PATH}\n",
    "# -C:                 task name is profiling\n",
    "# --simpoint-profile: run simpoint\n",
    "# --cpt-interval:     checkpoint interval (in instructions)\n",
    "${NEMU} ${GCPT} \\\n",
    "    -w ${WORKLOAD} \\\n",
    "    -D ${RESULT_PATH} \\\n",
    "    -C profiling \\\n",
    "    -b \\\n",
    "    --simpoint-profile \\\n",
    "    --cpt-interval ${CHECKPOINT_INTERVAL} \\\n",
    "    > >(tee ${_LOG_PATH}/${WORKLOAD}-out.txt) 2> >(tee ${_LOG_PATH}/${WORKLOAD}-err.txt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f686f3",
   "metadata": {},
   "source": [
    "进而，使用 SimPoint 对采集到的程序行为进行聚类分析，选取程序片段。\n",
    "\n",
    "Then, use SimPoint to perform clustering analysis on the collected program behavior, selecting segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5740d108",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "source 01-env.sh\n",
    "\n",
    "CLUSTER=${RESULT_PATH}/cluster/${WORKLOAD}\n",
    "mkdir -p ${CLUSTER}\n",
    "\n",
    "random1=`head -20 /dev/urandom | cksum | cut -c 1-6`\n",
    "random2=`head -20 /dev/urandom | cksum | cut -c 1-6`\n",
    "\n",
    "_LOG_PATH=${LOG_PATH}/cluster\n",
    "mkdir -p ${_LOG_PATH}\n",
    "\n",
    "# -loadFVFile          # load a frequency vector file\n",
    "# -saveSimpoints       # file to save simpoints\n",
    "# -saveSimpointWeights # file to save simpoints weights\n",
    "# -inputVectorsGzipped # input vectors have been compressed with gzip\n",
    "# -maxK                # maximum number of clusters to use\n",
    "# -numInitSeeds        # times of different random initialization for each run, taking only the best clustering\n",
    "# -iters               # maximum number of iterations that should perform\n",
    "# -seedkm              # random seed for choosing initial k-means centers\n",
    "# -seedproj            # random seed for random linear projection\n",
    "${SIMPOINT} \\\n",
    "    -loadFVFile ${PROFILING_RESULT_PATH}/${WORKLOAD}/simpoint_bbv.gz \\\n",
    "    -saveSimpoints ${CLUSTER}/simpoints0 \\\n",
    "    -saveSimpointWeights ${CLUSTER}/weights0 \\\n",
    "    -inputVectorsGzipped \\\n",
    "    -maxK 3 \\\n",
    "    -numInitSeeds 2 \\\n",
    "    -iters 1000 \\\n",
    "    -seedkm ${random1} \\\n",
    "    -seedproj ${random2} \\\n",
    "    > >(tee ${_LOG_PATH}/${WORKLOAD}-out.txt) 2> >(tee ${_LOG_PATH}/${WORKLOAD}-err.txt) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78f9afa",
   "metadata": {},
   "source": [
    "最后，使用 NEMU 重新运行需要采样的程序，生成 checkpoint。\n",
    "\n",
    "Finally, use NEMU to rerun the program that needs to be checkpointed to generate checkpoint files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f671d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "source 01-env.sh\n",
    "\n",
    "CLUSTER=${RESULT_PATH}/cluster\n",
    "_LOG_PATH=${LOG_PATH}/checkpoint\n",
    "mkdir -p ${_LOG_PATH}\n",
    "\n",
    "${NEMU} ${GCPT} \\\n",
    "    -w ${WORKLOAD} \\\n",
    "    -D ${RESULT_PATH} \\\n",
    "    -C checkpoint \\\n",
    "    -b \\\n",
    "    -S ${CLUSTER} \\\n",
    "    --cpt-interval ${CHECKPOINT_INTERVAL} \\\n",
    "    > >(tee ${_LOG_PATH}/${WORKLOAD}-out.txt) 2> >(tee ${_LOG_PATH}/${WORKLOAD}-err.txt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54b1408",
   "metadata": {},
   "source": [
    "前往目录 `${RESULT_PATH}/checkpoints`，可以看到生成的 checkpoint 文件，共有 cluster 数量个 `.gz` 文件，文件名上表明了 checkpoint 的权重。\n",
    "\n",
    "Go to the directory `${RESULT_PATH}/checkpoints`, you can see the generated checkpoint files, a total of cluster number of `.gz` files, with the weight of the checkpoint indicated in the file name.\n",
    "\n",
    "我们可以使用 emu 运行一下采集到的 checkpoint，看看效果。\n",
    "\n",
    "We can use emu to run one of the generated checkpoints and see the effect.\n",
    "\n",
    "emu 检测到文件是 gzip 压缩的 checkpoint 时，会自动进行解压缩，并从 checkpoint 恢复内存状态和体系结构状态。\n",
    "\n",
    "When emu detects that the file is a gzip-compressed checkpoint, it will automatically decompress it and restore the memory state and architectural state from the checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985fa0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "source 01-env.sh\n",
    "\n",
    "CHECKPOINT=$(find ${RESULT_PATH}/checkpoint/${WORKLOAD} -type f -name \"*_.gz\" | tail -1)\n",
    "\n",
    "$(get_asset emu-precompile/emu) \\\n",
    "    -i ${CHECKPOINT} \\\n",
    "    --diff $(get_asset emu-precompile/riscv64-nemu-interpreter-so) \\\n",
    "    --max-cycles=50000 \\\n",
    "    2>/dev/null\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a4cbfc",
   "metadata": {},
   "source": [
    "下面的 python 脚本可以生成 checkpoint 的配置文件，便于 GEM5/XiangShan 的批量运行。\n",
    "\n",
    "The following python script can generate configuration files for checkpoints, facilitating batch runs in GEM5/XiangShan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e080d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "from itertools import product\n",
    "\n",
    "app_list = [\n",
    "    \"bwaves\", \"gamess_cytosine\", \"gamess_gradient\", \"gamess_triazolium\",\n",
    "    \"milc\", \"zeusmp\", \"gromacs\", \"cactusADM\", \"leslie3d\", \"namd\", \"dealII\",\n",
    "    \"soplex_pds-50\", \"soplex_ref\", \"povray\", \"calculix\", \"GemsFDTD\", \"tonto\",\n",
    "    \"lbm\", \"wrf\", \"sphinx3\"\n",
    "]\n",
    "\n",
    "spec_2017_list = [\n",
    "    \"bwaves_1\", \"bwaves_2\", \"bwaves_3\", \"bwaves_4\", \"cactuBSSN\", \"namd\",\n",
    "    \"parest\", \"povray\", \"lbm\", \"wrf\", \"blender\", \"cam4\", \"imagick\", \"nab\",\n",
    "    \"fotonik3d\", \"roms\", \"perlbench_diff\", \"perlbench_spam\", \"perlbench_split\",\n",
    "    \"gcc_pp_O2\", \"gcc_pp_O3\", \"gcc_ref32_O3\", \"gcc_ref32_O5\", \"gcc_small_O3\",\n",
    "    \"mcf\", \"omnetpp\", \"xalancbmk\", \"x264_pass1\", \"x264_pass2\", \"x264_seek\",\n",
    "    \"deepsjeng\", \"leela\", \"exchange2\", \"xz_cld\", \"xz_combined\", \"xz_cpu2006\"\n",
    "]\n",
    "\n",
    "spec2017_int_list = [\n",
    "    \"perlbench_diff\", \"perlbench_spam\", \"perlbench_split\", \"gcc_pp_O2\",\n",
    "    \"gcc_pp_O3\", \"gcc_ref32_O3\", \"gcc_ref32_O5\", \"gcc_small_O3\", \"mcf\",\n",
    "    \"omnetpp\", \"xalancbmk\", \"x264_pass1\", \"x264_pass2\", \"x264_seek\",\n",
    "    \"deepsjeng\", \"leela\", \"exchange2\", \"xz_cld\", \"xz_combined\", \"xz_cpu2006\"\n",
    "]\n",
    "\n",
    "spec2017_fp_list = list(set(spec_2017_list) - set(spec2017_int_list))\n",
    "\n",
    "\n",
    "def profiling_instrs(profiling_log, spec_app, using_new_script=False):\n",
    "    regex = r\".*total guest instructions = (.*)\\x1b.*\"\n",
    "    new_path = os.path.join(profiling_log, spec_app, \"profiling.out.log\")\n",
    "    old_path = os.path.join(profiling_log, \"{}-out.txt\".format(spec_app))\n",
    "\n",
    "    if using_new_script:\n",
    "        path = new_path\n",
    "    else:\n",
    "        path = old_path\n",
    "\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for i in f.readlines():\n",
    "            if \"total guest instructions\" in i:\n",
    "                match = re.findall(regex, i)\n",
    "                match = match[0].replace(',', '')\n",
    "                return match\n",
    "        return 0\n",
    "\n",
    "\n",
    "def cluster_weight(cluster_path, spec_app):\n",
    "    points = {}\n",
    "    weights = {}\n",
    "\n",
    "    weights_path = f\"{cluster_path}/{spec_app}/weights0\"\n",
    "    simpoints_path = f\"{cluster_path}/{spec_app}/simpoints0\"\n",
    "\n",
    "    with open(weights_path, \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            a, b = line.split()\n",
    "            weights.update({\"{}\".format(b): \"{}\".format(a)})\n",
    "\n",
    "    with open(simpoints_path, \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            a, b = line.split()\n",
    "            points.update({a: weights.get(b)})\n",
    "\n",
    "    return points\n",
    "\n",
    "\n",
    "def per_checkpoint_generate_json(profiling_log, cluster_path, app_list,\n",
    "                                 target_path):\n",
    "    result = {}\n",
    "    for spec in app_list:\n",
    "        result.update({\n",
    "            spec: {\n",
    "                \"insts\": profiling_instrs(profiling_log, spec),\n",
    "                'points': cluster_weight(cluster_path, spec)\n",
    "            }\n",
    "        })\n",
    "    with open(os.path.join(target_path), \"w\") as f:\n",
    "        f.write(json.dumps(result))\n",
    "\n",
    "\n",
    "def per_checkpoint_generate_worklist(cpt_path, target_path):\n",
    "    cpt_path = cpt_path + \"/\"\n",
    "    checkpoints = []\n",
    "    for item in os.scandir(cpt_path):\n",
    "        if item.is_dir():\n",
    "            checkpoints.append(item.path)\n",
    "\n",
    "    checkpoint_dirs = []\n",
    "    for item in checkpoints:\n",
    "        for entry in os.scandir(item):\n",
    "            checkpoint_dirs.append(entry.path)\n",
    "\n",
    "    with open(target_path, \"w\") as f:\n",
    "        for i in checkpoint_dirs:\n",
    "            path = i.replace(cpt_path, \"\")\n",
    "            name = path.replace('/', \"_\", 1)\n",
    "            print(\"{} {} 0 0 20 20\".format(name, path), file=f)\n",
    "\n",
    "\n",
    "def generate_result_list(base_path, times, ids):\n",
    "    result_list = []\n",
    "\n",
    "    for i, j, k in product(range(ids[0], times[0]), range(ids[1], times[1]),\n",
    "                           range(ids[2], times[2])):\n",
    "        cluster = f\"cluster\"\n",
    "        profiling = f\"profiling\"\n",
    "        checkpoint = f\"checkpoint\"\n",
    "        result_list.append({\n",
    "            \"cl_res\": os.path.join(base_path, \"result\", cluster),\n",
    "            \"profiling_log\": os.path.join(base_path, \"logs\", profiling),\n",
    "            \"checkpoint_path\": os.path.join(base_path, \"result\", checkpoint),\n",
    "            \"json_path\": os.path.join(base_path, \"result\", checkpoint, f\"{cluster}.json\"),\n",
    "            \"list_path\": os.path.join(base_path, \"result\", checkpoint, \"checkpoint.lst\"),\n",
    "        })\n",
    "\n",
    "    print(\"Result list:\")\n",
    "    print(json.dumps(result_list, indent=2, separators=(\",\", \": \")))\n",
    "    return result_list\n",
    "\n",
    "\n",
    "\n",
    "def dump_result(base_path, spec_app_list, times, ids):\n",
    "    result_list = generate_result_list(base_path, times, ids)\n",
    "\n",
    "    for result in result_list:\n",
    "        per_checkpoint_generate_json(result[\"profiling_log\"], result[\"cl_res\"],\n",
    "                                     spec_app_list, result[\"json_path\"])\n",
    "        per_checkpoint_generate_worklist(result[\"checkpoint_path\"],\n",
    "                                         result[\"list_path\"])\n",
    "\n",
    "\n",
    "# NOTE: should be same with 01-checkpoint-env.sh\n",
    "spec_list=[\"stream_100000\"]\n",
    "base_path = os.path.join(os.getcwd(), \"..\", \"work\", \"03-performance\", \"01-checkpoint\")\n",
    "times = [1, 1, 1]\n",
    "ids = [0, 0, 0]\n",
    "\n",
    "dump_result(base_path, spec_list, times, ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab155a8d",
   "metadata": {},
   "source": [
    "结果生成在 `${RESULT_PATH}/checkpoints` 目录下。\n",
    "\n",
    "The results are generated in the `${RESULT_PATH}/checkpoints` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7492e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "source 01-env.sh\n",
    "\n",
    "# list file for GEM5\n",
    "cat ${RESULT_PATH}/checkpoint/checkpoint.lst\n",
    "echo\n",
    "\n",
    "# json file for XiangShan\n",
    "cat ${RESULT_PATH}/checkpoint/cluster.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07fb6ad",
   "metadata": {},
   "source": [
    "附：Checkpoint 的文件结构如下所示（低地址在上）：\n",
    "\n",
    "File structure of a checkpoint is as follows(low address at the top):\n",
    "\n",
    "![structure](../images/03-performance/01-checkpoint/structure-en.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
