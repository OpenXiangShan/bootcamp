{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72f6be59",
   "metadata": {},
   "source": [
    "# Checkpoint 与性能评估\n",
    "使用 checkpoint 进行性能评估在学术界和工业界都有广泛应用。为了生成 checkpoint，我们首先需要准备 NEMU 环境，并得到 GCPT restorer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec68f27",
   "metadata": {},
   "source": [
    "本节中会用到一些与 `xs-env/env.sh` 不同的路径和常量，为了方便使用，我们创建了一个 `07-checkpoint-env.sh`，在本节中我们将使用该脚本设置环境变量，您可以运行下面的单元格查看这些环境变量。在后续的单元格中我们仍将输出重定向到 `/dev/null` 减少干扰。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad19b46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "source 07-checkpoint-env.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3c7693",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "source 07-checkpoint-env.sh >/dev/null\n",
    "\n",
    "cd ${NEMU_HOME}\n",
    "git submodule update --init\n",
    "\n",
    "# 编译 simpoint\n",
    "cd ${NEMU_HOME}/resource/simpoint/simpoint_repo\n",
    "make clean\n",
    "make\n",
    "\n",
    "# 编译 NEMU\n",
    "cd ${NEMU_HOME}\n",
    "make clean\n",
    "make riscv64-xs-cpt_defconfig\n",
    "make -j8\n",
    "\n",
    "cd ${NEMU_HOME}/resource/gcpt_restore\n",
    "rm -rf ${GCPT_PATH}\n",
    "make -C ${NEMU_HOME}/resource/gcpt_restore/ O=${GCPT_PATH} GCPT_PAYLOAD_PATH=${PAYLOAD_PATH}/${WORKLOAD}.bin CROSS_COMPILE=riscv64-linux-gnu-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b078a55",
   "metadata": {},
   "source": [
    "接下来，我们需要使用 NEMU 运行要进行切片的程序，来收集程序行为"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6105c94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "source 07-checkpoint-env.sh >/dev/null\n",
    "\n",
    "rm -rf $RESULT_PATH\n",
    "\n",
    "_LOG_PATH=$LOG_PATH/profiling\n",
    "mkdir -p $_LOG_PATH\n",
    "\n",
    "# 使用 GCPT 作为镜像\n",
    "# -w：要加载的实际负载为 WORKLOAD\n",
    "# -C：使用 profiling 配置运行 NEMU\n",
    "$NEMU ${GCPT} \\\n",
    "    -D ${RESULT_PATH} \\\n",
    "    -w ${WORKLOAD} \\\n",
    "    -C profiling \\\n",
    "    -b \\\n",
    "    --simpoint-profile \\\n",
    "    --cpt-interval ${CHECKPOINT_INTERVAL} \\\n",
    "    > >(tee ${_LOG_PATH}/${WORKLOAD}-out.txt) 2> >(tee ${_LOG_PATH}/${WORKLOAD}-err.txt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f686f3",
   "metadata": {},
   "source": [
    "进而，使用 simpoint 对采集到的程序行为进行聚类分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5740d108",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "source 07-checkpoint-env.sh >/dev/null\n",
    "\n",
    "CLUSTER=${RESULT_PATH}/cluster/${WORKLOAD}\n",
    "mkdir -p ${CLUSTER}\n",
    "\n",
    "random1=`head -20 /dev/urandom | cksum | cut -c 1-6`\n",
    "random2=`head -20 /dev/urandom | cksum | cut -c 1-6`\n",
    "\n",
    "_LOG_PATH=$LOG_PATH/cluster\n",
    "mkdir -p $_LOG_PATH\n",
    "\n",
    "$SIMPOINT \\\n",
    "    -loadFVFile ${PROFILING_RESULT_PATH}/${WORKLOAD}/simpoint_bbv.gz \\\n",
    "    -saveSimpoints ${CLUSTER}/simpoints0 \\\n",
    "    -saveSimpointWeights ${CLUSTER}/weights0 \\\n",
    "    -inputVectorsGzipped \\\n",
    "    -maxK 3 \\\n",
    "    -numInitSeeds 2 \\\n",
    "    -iters 1000 \\\n",
    "    -seedkm ${random1} \\\n",
    "    -seedproj ${random2} \\\n",
    "    > >(tee ${_LOG_PATH}/${WORKLOAD}-out.txt) 2> >(tee ${_LOG_PATH}/${WORKLOAD}-err.txt) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78f9afa",
   "metadata": {},
   "source": [
    "最后，使用 NEMU 重新运行需要采样的程序片段，生成 checkpoint。\n",
    "\n",
    "checkpoint 文件内包括需要执行的程序段，也包括 checkpoint 起始位置时的内存状态和处理器体系结构状态（通用寄存器堆，CSR）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f671d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "source 07-checkpoint-env.sh >/dev/null\n",
    "\n",
    "CLUSTER=${RESULT_PATH}/cluster\n",
    "_LOG_PATH=${LOG_PATH}/checkpoint\n",
    "mkdir -p ${_LOG_PATH}\n",
    "\n",
    "$NEMU ${GCPT} \\\n",
    "    -D ${RESULT_PATH} \\\n",
    "    -w ${WORKLOAD} \\\n",
    "    -C checkpoint \\\n",
    "    -b \\\n",
    "    -S ${CLUSTER} \\\n",
    "    --cpt-interval ${CHECKPOINT_INTERVAL} \\\n",
    "    > >(tee ${_LOG_PATH}/${WORKLOAD}-out.txt) 2> >(tee ${_LOG_PATH}/${WORKLOAD}-err.txt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54b1408",
   "metadata": {},
   "source": [
    "我们可以使用 emu 运行一下采集到的 checkpoint，看看效果。\n",
    "\n",
    "emu 检测到文件是 gzip 压缩的 checkpoint 时，会自动进行解压缩，并从 checkpoint 恢复内存状态和体系结构状态。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985fa0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "source 07-checkpoint-env.sh >/dev/null\n",
    "\n",
    "CHECKPOINT=$(find ${RESULT_PATH}/checkpoint/${WORKLOAD} -type f -name \"*_.gz\" | tail -1)\n",
    "\n",
    "${READY2RUN_HOME}/emu \\\n",
    "    -i ${CHECKPOINT} \\\n",
    "    --diff ${NOOP_HOME}/ready-to-run/riscv64-nemu-interpreter-so \\\n",
    "    --max-cycles=50000 \\\n",
    "    2>/dev/null\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e080d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "from itertools import product\n",
    "\n",
    "app_list = [\n",
    "    \"bwaves\", \"gamess_cytosine\", \"gamess_gradient\", \"gamess_triazolium\",\n",
    "    \"milc\", \"zeusmp\", \"gromacs\", \"cactusADM\", \"leslie3d\", \"namd\", \"dealII\",\n",
    "    \"soplex_pds-50\", \"soplex_ref\", \"povray\", \"calculix\", \"GemsFDTD\", \"tonto\",\n",
    "    \"lbm\", \"wrf\", \"sphinx3\"\n",
    "]\n",
    "\n",
    "spec_2017_list = [\n",
    "    \"bwaves_1\", \"bwaves_2\", \"bwaves_3\", \"bwaves_4\", \"cactuBSSN\", \"namd\",\n",
    "    \"parest\", \"povray\", \"lbm\", \"wrf\", \"blender\", \"cam4\", \"imagick\", \"nab\",\n",
    "    \"fotonik3d\", \"roms\", \"perlbench_diff\", \"perlbench_spam\", \"perlbench_split\",\n",
    "    \"gcc_pp_O2\", \"gcc_pp_O3\", \"gcc_ref32_O3\", \"gcc_ref32_O5\", \"gcc_small_O3\",\n",
    "    \"mcf\", \"omnetpp\", \"xalancbmk\", \"x264_pass1\", \"x264_pass2\", \"x264_seek\",\n",
    "    \"deepsjeng\", \"leela\", \"exchange2\", \"xz_cld\", \"xz_combined\", \"xz_cpu2006\"\n",
    "]\n",
    "\n",
    "spec2017_int_list = [\n",
    "    \"perlbench_diff\", \"perlbench_spam\", \"perlbench_split\", \"gcc_pp_O2\",\n",
    "    \"gcc_pp_O3\", \"gcc_ref32_O3\", \"gcc_ref32_O5\", \"gcc_small_O3\", \"mcf\",\n",
    "    \"omnetpp\", \"xalancbmk\", \"x264_pass1\", \"x264_pass2\", \"x264_seek\",\n",
    "    \"deepsjeng\", \"leela\", \"exchange2\", \"xz_cld\", \"xz_combined\", \"xz_cpu2006\"\n",
    "]\n",
    "\n",
    "spec2017_fp_list = list(set(spec_2017_list) - set(spec2017_int_list))\n",
    "\n",
    "\n",
    "def profiling_instrs(profiling_log, spec_app, using_new_script=False):\n",
    "    regex = r\".*total guest instructions = (.*)\\x1b.*\"\n",
    "    new_path = os.path.join(profiling_log, spec_app, \"profiling.out.log\")\n",
    "    old_path = os.path.join(profiling_log, \"{}-out.txt\".format(spec_app))\n",
    "\n",
    "    if using_new_script:\n",
    "        path = new_path\n",
    "    else:\n",
    "        path = old_path\n",
    "\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for i in f.readlines():\n",
    "            if \"total guest instructions\" in i:\n",
    "                match = re.findall(regex, i)\n",
    "                match = match[0].replace(',', '')\n",
    "                return match\n",
    "        return 0\n",
    "\n",
    "\n",
    "def cluster_weight(cluster_path, spec_app):\n",
    "    points = {}\n",
    "    weights = {}\n",
    "\n",
    "    weights_path = f\"{cluster_path}/{spec_app}/weights0\"\n",
    "    simpoints_path = f\"{cluster_path}/{spec_app}/simpoints0\"\n",
    "\n",
    "    with open(weights_path, \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            a, b = line.split()\n",
    "            weights.update({\"{}\".format(b): \"{}\".format(a)})\n",
    "\n",
    "    with open(simpoints_path, \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            a, b = line.split()\n",
    "            points.update({a: weights.get(b)})\n",
    "\n",
    "    return points\n",
    "\n",
    "\n",
    "def per_checkpoint_generate_json(profiling_log, cluster_path, app_list,\n",
    "                                 target_path):\n",
    "    result = {}\n",
    "    for spec in app_list:\n",
    "        result.update({\n",
    "            spec: {\n",
    "                \"insts\": profiling_instrs(profiling_log, spec),\n",
    "                'points': cluster_weight(cluster_path, spec)\n",
    "            }\n",
    "        })\n",
    "    with open(os.path.join(target_path), \"w\") as f:\n",
    "        f.write(json.dumps(result))\n",
    "\n",
    "\n",
    "def per_checkpoint_generate_worklist(cpt_path, target_path):\n",
    "    cpt_path = cpt_path + \"/\"\n",
    "    checkpoints = []\n",
    "    for item in os.scandir(cpt_path):\n",
    "        if item.is_dir():\n",
    "            checkpoints.append(item.path)\n",
    "\n",
    "    checkpoint_dirs = []\n",
    "    for item in checkpoints:\n",
    "        for entry in os.scandir(item):\n",
    "            checkpoint_dirs.append(entry.path)\n",
    "\n",
    "    with open(target_path, \"w\") as f:\n",
    "        for i in checkpoint_dirs:\n",
    "            path = i.replace(cpt_path, \"\")\n",
    "            name = path.replace('/', \"_\", 1)\n",
    "            print(\"{} {} 0 0 20 20\".format(name, path), file=f)\n",
    "\n",
    "\n",
    "def generate_result_list(base_path, times, ids):\n",
    "    result_list = []\n",
    "\n",
    "    for i, j, k in product(range(ids[0], times[0]), range(ids[1], times[1]),\n",
    "                           range(ids[2], times[2])):\n",
    "        cluster = f\"cluster\"\n",
    "        profiling = f\"profiling\"\n",
    "        checkpoint = f\"checkpoint\"\n",
    "        result_list.append({\n",
    "            \"cl_res\": os.path.join(base_path, \"result\", cluster),\n",
    "            \"profiling_log\": os.path.join(base_path, \"logs\", profiling),\n",
    "            \"checkpoint_path\": os.path.join(base_path, \"result\", checkpoint),\n",
    "            \"json_path\": os.path.join(base_path, \"result\", checkpoint, f\"{cluster}.json\"),\n",
    "            \"list_path\": os.path.join(base_path, \"result\", checkpoint, \"checkpoint.lst\"),\n",
    "        })\n",
    "\n",
    "    print(\"Result list:\")\n",
    "    print(json.dumps(result_list, indent=2, separators=(\",\", \": \")))\n",
    "    return result_list\n",
    "\n",
    "\n",
    "\n",
    "def dump_result(base_path, spec_app_list, times, ids):\n",
    "    result_list = generate_result_list(base_path, times, ids)\n",
    "\n",
    "    for result in result_list:\n",
    "        per_checkpoint_generate_json(result[\"profiling_log\"], result[\"cl_res\"],\n",
    "                                     spec_app_list, result[\"json_path\"])\n",
    "        per_checkpoint_generate_worklist(result[\"checkpoint_path\"],\n",
    "                                         result[\"list_path\"])\n",
    "\n",
    "\n",
    "# NOTE: should be same with 07-checkpoint-env.sh\n",
    "spec_list=[\"stream_100000\"]\n",
    "base_path = os.path.join(os.getcwd(), \"07-checkpoint\")\n",
    "times = [1, 1, 1]\n",
    "ids = [0, 0, 0]\n",
    "\n",
    "dump_result(base_path, spec_list, times, ids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
